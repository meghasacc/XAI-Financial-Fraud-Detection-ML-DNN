# Explainable AI-Driven Financial Transaction Fraud Detection Application using Machine Learning and Deep Neural Networks
## Introduction

<p align = 'justify' > Artificial Intelligence (AI) has entered the business mainstream opening new opportunities to solve the most complex business problems. In the Covid-19 pandemic, the use of online payments has skyrocketed, and the world is making an inexorable shift toward digital transformation by using more cards and mobile apps instead of cash. </p>

<p align = 'justify' > As per Statista research, Visa is the market leader among digital payment processors in the world with more than $10 trillion in transactions, followed by Apple Pay and Alipay. In UK E-commerce, Visa and Mastercard are the most frequently used payment options. These payment options are available from 98% of the top 500 online retailers in 2020. </p>

## Impact of AI in Finance & Banking

<p align = 'justify' >The finance and banking industry has benefited from digital technologies like AI, creating a new discipline of FinTech. AI is projected to save the banking industry approx $1 trillion by 2030 and $447 billion by 2023. </p>

<p align = 'justify' >AI is used in FinTech to create solutions to the problems that traditional finance and banking sectors like Fraud Detection, Risk Management, Investment Management, Predictive Analytics and Anti-Money Laundering. </p>


## Financial Transaction Fraud Detection

<p align = 'justify' >While digitisation creates opportunities for development and growth, it also attracts cybercriminals and fraudsters for financial fraud which has become a major business problem in the financial and banking industry. </p>

<p align = 'justify' >Fraud losses increased by 30% and fraudsters have stolen £754 million from bank financial transactions and 76% of CC fraud losses in the UK were due to Card-not-Present (CNP) totalling £470.2 million (UK Finance, 2021).</p>


## Explainable AI (XAI)

<p align = 'justify' > Explainable AI (XAI) is an emerging branch of AI that focuses on converting complex 'black-box' AI algorithms and system outputs into clearly understandable, trustable, or so-called 'white-box' AI algorithms.</p>

<p align = 'justify' >With XAI, black-box AI models are more explainable, intuitive, and understandable to business decision-makers without sacrificing performance or prediction accuracy.</p>

<p align = 'justify' >This research project tackled and filled the gap of the lack of explainability by implementing an Explainable AI (XAI)-driven Interface and a Proof of Concept (POC) Web Application for Financial Transaction Fraud Detection using Machine Learning (ML) & Deep Neural Network (DNN).</p>

<p align = 'justify' >Therefore, XAI-driven financial transaction fraud detection system predictions can be operationalized into production with greater confidence, trust and transparency. This will save a surplus revenue, better forecasts, and greater understandability, reduce uncertainty in business decisions and prevent fraud in financial services and the banking industry.</p>











